# ğŸ½ï¸ Snap2Recipe

**Detect ingredients from food photos and discover delicious recipes**

A production-ready, open-source web application that uses computer vision to identify ingredients from food images and suggests matching recipes using intelligent search algorithms.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.11-blue.svg)
![Next.js](https://img.shields.io/badge/next.js-14-black.svg)
![FastAPI](https://img.shields.io/badge/fastapi-0.104+-green.svg)

## âœ¨ Features

- ğŸ“¸ **Image Upload**: Drag-and-drop or click to upload food photos
- ğŸ” **Ingredient Detection**: AI-powered ingredient recognition using PyTorch
- ğŸ³ **Recipe Suggestions**: Smart recipe matching with BM25 ranking
- ğŸ·ï¸ **Ingredient Selection**: Toggle detected ingredients to refine search
- ğŸ“š **Recipe Details**: View full ingredients, instructions, cooking time, and cuisine
- ğŸ“œ **History**: Keep track of your last 5 detections (localStorage)
- ğŸ¨ **Modern UI**: Beautiful, responsive design with Tailwind CSS and shadcn/ui
- ğŸ³ **Docker Ready**: One-command deployment with docker-compose

## ğŸ—ï¸ Architecture

```
snap2recipe/
â”œâ”€â”€ api/                    # FastAPI backend
â”‚   â”œâ”€â”€ model/             # ML model loader (PyTorch)
â”‚   â”œâ”€â”€ recipes/           # Recipe indexing (BM25)
â”‚   â”œâ”€â”€ utils/             # Text normalization
â”‚   â”œâ”€â”€ main.py            # FastAPI app
â”‚   â”œâ”€â”€ schemas.py         # Pydantic models
â”‚   â””â”€â”€ tests/             # Backend tests
â”œâ”€â”€ web/                   # Next.js 14 frontend
â”‚   â”œâ”€â”€ app/               # App router pages
â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”œâ”€â”€ lib/               # API client & utilities
â”‚   â””â”€â”€ tests/             # E2E tests (Playwright)
â”œâ”€â”€ data/                  # Recipe data & synonyms
â”‚   â”œâ”€â”€ recipes.csv        # Recipe database
â”‚   â””â”€â”€ synonyms.json      # Ingredient synonyms
â”œâ”€â”€ docker-compose.yml     # Orchestration
â””â”€â”€ Makefile              # Development commands
```

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- OR: Python 3.11+ and Node.js 18+

### Option 1: Docker (Recommended)

```bash
# Clone the repository
git clone <your-repo-url>
cd snap2recipe

# Start all services
make dev
# or
docker-compose up
```

The app will be available at:
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

### Option 2: Local Development

#### Backend Setup

```bash
cd api

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('wordnet'); nltk.download('omw-1.4')"

# Run the server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

#### Frontend Setup

```bash
cd web

# Install dependencies
npm install

# Create environment file
cp .env.local.example .env.local

# Run development server
npm run dev
```

## ğŸ“– Usage

1. **Upload a Food Photo**
   - Drag and drop an image or click to browse
   - Supports JPG, PNG, WebP formats

2. **Detect Ingredients**
   - Click "Detect Ingredients" button
   - AI model analyzes the image and identifies ingredients

3. **Refine Selection**
   - Toggle ingredients on/off by clicking chips
   - Confidence scores shown as percentages

4. **Find Recipes**
   - Click "Find Recipes" to search
   - Results ranked by ingredient match score

5. **Explore Recipes**
   - View recipe cards with key details
   - Expand to see full ingredients and instructions
   - Filter by cuisine, tags, and cooking time

## ğŸ§ª Testing

### Backend Tests

```bash
cd api
pytest tests/ -v
```

### Frontend Tests

```bash
cd web
npm test
```

## ğŸ› ï¸ Development

### Available Commands

```bash
make install    # Install all dependencies
make dev        # Start development environment
make build      # Build Docker images
make test       # Run all tests
make clean      # Clean build artifacts
```

### Backend API Endpoints

- `GET /` - API information
- `GET /health` - Health check
- `POST /detect` - Detect ingredients from image
- `GET /recipes?s=ing1,ing2` - Search recipes by ingredients
- `POST /suggest` - Suggest recipes (POST body)
- `GET /recipes/{id}` - Get specific recipe

### Environment Variables

**Backend (`api/.env`)**
```env
MODEL_WEIGHTS_PATH=./model/weights
MODEL_DEVICE=cpu
MODEL_CONFIDENCE_THRESHOLD=0.3
RECIPES_PATH=../data/recipes.csv
SYNONYMS_PATH=../data/synonyms.json
CORS_ORIGINS=http://localhost:3000
```

**Frontend (`web/.env.local`)**
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ¤– ML Model

The ingredient detection uses a PyTorch-based model with fallback to COCO-pretrained Faster R-CNN:

- **Primary**: Custom food recognition model (when weights provided)
- **Fallback**: torchvision's Faster R-CNN with food-related COCO classes
- **Inference**: CPU by default, configurable to GPU
- **Caching**: LRU cache for recent predictions

To use custom weights:
1. Place model weights in `api/model/weights/`
2. Set `MODEL_WEIGHTS_PATH` environment variable

## ğŸ” Recipe Search

The recipe search uses **BM25 (Best Matching 25)** ranking algorithm:

- **Text Normalization**: Lowercasing, lemmatization, stopword removal
- **Synonym Mapping**: Handles ingredient variations (e.g., "capsicum" â†’ "bell pepper")
- **Plural Handling**: Automatic singular/plural normalization
- **Scoring**: Relevance-based ranking with configurable parameters

## ğŸ“Š Data

### Recipe Format (`data/recipes.csv`)

```csv
id,title,ingredients,instructions,cuisine,tags,time_minutes
1,Margherita Pizza,"tomato sauce, mozzarella, basil","Roll dough...",Italian,"vegetarian,quick",30
```

### Synonym Mapping (`data/synonyms.json`)

```json
{
  "capsicum": "bell pepper",
  "garbanzo": "chickpea",
  "scallion": "green onion"
}
```

## ğŸ¨ Frontend Components

- **UploadBox**: Drag-and-drop image upload with preview
- **IngredientChips**: Selectable ingredient tags with confidence scores
- **RecipeCard**: Expandable recipe cards with details
- **LoadingOverlay**: Loading states for async operations
- **HistoryDrawer**: Sidebar with recent detection history

## ğŸ³ Docker Deployment

### Production Build

```bash
# Build images
docker-compose build

# Run in production mode
docker-compose up -d
```

### Scaling

```bash
# Scale API service
docker-compose up -d --scale api=3
```

## ğŸ”§ Configuration

### Adding More Recipes

1. Edit `data/recipes.csv`
2. Follow the CSV format
3. Restart the API service

### Adding Synonyms

1. Edit `data/synonyms.json`
2. Add key-value pairs
3. Restart the API service

### Customizing UI

- Colors: Edit `web/app/globals.css` CSS variables
- Components: Modify files in `web/components/`
- Styling: Tailwind classes in component files

## ğŸ“ API Documentation

Interactive API documentation available at:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- PyTorch team for the deep learning framework
- FastAPI for the excellent Python web framework
- Next.js team for the React framework
- Vercel for shadcn/ui components
- COCO dataset for pretrained models

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

**Built with â¤ï¸ using FastAPI, Next.js, and PyTorch**
